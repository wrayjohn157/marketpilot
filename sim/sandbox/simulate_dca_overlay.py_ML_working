#!/usr/bin/env python3
import argparse
import json
from pathlib import Path
from datetime import datetime

import pandas as pd
from ta.trend import MACD
from ta.momentum import RSIIndicator
import yaml
import joblib

# === CONFIG ===
BASE_DIR = Path(__file__).resolve().parent.parent.parent
KLINE_PATH = BASE_DIR / "data" / "klines"
CONFIG_PATH = BASE_DIR / "sim" / "config" / "dca_config.yaml"


def load_klines(symbol: str, tf: str, entry_ts: int) -> pd.DataFrame:
    date_str = datetime.utcfromtimestamp(entry_ts).strftime("%Y-%m-%d")
    fname = f"{symbol.upper()}_{tf}_klines.json"
    kline_file = BASE_DIR / "data" / "snapshots" / date_str / fname
    if not kline_file.exists():
        raise FileNotFoundError(f"No kline data at {kline_file}")
    df = pd.read_json(kline_file, orient="values")
    df.columns = [
        "timestamp",
        "open",
        "high",
        "low",
        "close",
        "volume",
        "close_time",
        "quote_asset_volume",
        "number_of_trades",
        "taker_buy_base",
        "taker_buy_quote",
        "ignore",
    ]
    print(f"Loaded columns: {df.columns.tolist()}")  # Debug line

    return df[df["timestamp"] >= entry_ts].copy()


def add_indicators(df: pd.DataFrame) -> pd.DataFrame:
    df["RSI"] = RSIIndicator(close=df["close"], window=14).rsi()
    macd = MACD(close=df["close"])
    df["MACD"] = macd.macd()
    df["MACD_signal"] = macd.macd_signal()
    df["MACD_hist"] = macd.macd_diff()
    return df


def simulate_dca(df: pd.DataFrame, entry_price: float, config: dict, confidence_model=None, recovery_model=None) -> list:
    steps = []
    drawdown_trigger = config.get("drawdown_trigger_pct", 0.9)
    indicator_thresholds = config.get("indicator_thresholds", {})
    use_trajectory = config.get("use_trajectory_check", False)
    trajectory_thresholds = config.get("trajectory_thresholds", {})

    # --- DCA gating config sections ---
    use_soft_confidence_override = config.get("use_soft_confidence_override", False)
    soft_confidence_override = config.get("soft_confidence_override", 0)
    use_confidence_override = config.get("use_confidence_override", False)
    confidence_dca_guard = config.get("confidence_dca_guard", 0)
    require_tp1_feasibility = config.get("require_tp1_feasibility", False)
    max_tp1_shift_pct = config.get("max_tp1_shift_pct", 10)
    require_recovery_odds = config.get("require_recovery_odds", False)
    min_recovery_probability = config.get("min_recovery_probability", 0.0)
    min_confidence_odds = config.get("min_confidence_odds", 0.0)
    min_be_improvement_pct = config.get("min_be_improvement_pct", 0.0)
    use_safu_exit_model = config.get("use_safu_exit_model", False)
    ml_exit_threshold = config.get("ml_exit_threshold", 0.0)
    step_progress_guard = config.get("step_progress_guard", None)

    fired_prices = [entry_price]
    avg_entry_price = entry_price

    last_fire = None
    last_fire_ts = None
    last_price = None
    last_drawdown_pct = None

    prev_row = None

    for i, row in df.iterrows():
        drawdown_pct = round((row["close"] - avg_entry_price) / avg_entry_price * 100, 2)
        if prev_row is None:
            prev_row = row
            continue

        log = {
            "timestamp": int(row["timestamp"]),
            "price": row["close"],
            "decision": "HOLD",
        }

        # Recalculate average entry price and drawdown
        log["drawdown_pct"] = drawdown_pct
        log["avg_entry_price"] = round(avg_entry_price, 4)
        log["dca_count"] = len(fired_prices) - 1

        # Check drawdown
        if drawdown_pct > -drawdown_trigger:
            log["rejection_reason"] = "Drawdown not deep enough"
            steps.append(log)
            prev_row = row
            continue

        # Check indicators
        rsi_ok = row["RSI"] >= indicator_thresholds.get("rsi", 0)
        macd_ok = row["MACD_hist"] >= indicator_thresholds.get("macd_histogram", 0)
        adx_ok = row.get("ADX", 20) >= indicator_thresholds.get("adx", 0)

        if not (rsi_ok and macd_ok and adx_ok):
            log["rejection_reason"] = "Indicator thresholds not met"
            steps.append(log)
            prev_row = row
            continue

        # Trajectory check
        if use_trajectory:
            macd_lift = row["MACD_hist"] - row["MACD_signal"]
            rsi_slope = row["RSI"] - df.iloc[i - 1]["RSI"] if i > 0 else 0
            if macd_lift < trajectory_thresholds.get("macd_lift_min", 0) or rsi_slope < trajectory_thresholds.get("rsi_slope_min", 0):
                log["rejection_reason"] = "Trajectory thresholds not met"
                steps.append(log)
                prev_row = row
                continue

        # --- Simulate DCA gating system ---
        if confidence_model:
            features = pd.DataFrame([{
                "step": len(fired_prices),
                "entry_score": row.get("MACD_hist", 0),
                "current_score": row.get("MACD_hist", 0),
                "tp1_shift": abs(drawdown_pct),
                "safu_score": 0.5,
                "rsi": row.get("RSI", 0),
                "macd_histogram": row.get("MACD_hist", 0),
                "adx": row.get("ADX", 20),
                "macd_lift": row.get("MACD_hist", 0) - row.get("MACD_signal", 0),
                "rsi_slope": row.get("RSI", 0) - prev_row.get("RSI", 0),
                "drawdown_pct": drawdown_pct,
                "snapshot_score_trend": row.get("MACD_hist", 0) - prev_row.get("MACD_hist", 0),
                "snapshot_rsi_trend": row.get("RSI", 0) - prev_row.get("RSI", 0),
                "snapshot_max_drawdown": abs(drawdown_pct),
                "snapshot_min_score": min(row.get("MACD_hist", 0), prev_row.get("MACD_hist", 0)),
                "snapshot_min_rsi": min(row.get("RSI", 0), prev_row.get("RSI", 0)),
                "snapshot_time_to_max_drawdown_min": 0
            }])
            current_confidence = float(confidence_model.predict(features)[0])
        else:
            current_confidence = round(row["RSI"] / 100, 2)

        if recovery_model:
            features = pd.DataFrame([{
                "entry_score": row.get("MACD_hist", 0),
                "current_score": row.get("MACD_hist", 0),
                "drawdown_pct": drawdown_pct,
                "safu_score": 0.5,
                "rsi": row.get("RSI", 0),
                "macd_histogram": row.get("MACD_hist", 0),
                "adx": row.get("ADX", 20),
                "macd_lift": row.get("MACD_hist", 0) - row.get("MACD_signal", 0),
                "rsi_slope": row.get("RSI", 0) - prev_row.get("RSI", 0),
                "snapshot_score_trend": row.get("MACD_hist", 0) - prev_row.get("MACD_hist", 0),
                "snapshot_rsi_trend": row.get("RSI", 0) - prev_row.get("RSI", 0),
                "snapshot_max_drawdown": abs(drawdown_pct),
                "snapshot_min_score": min(row.get("MACD_hist", 0), prev_row.get("MACD_hist", 0)),
                "snapshot_min_rsi": min(row.get("RSI", 0), prev_row.get("RSI", 0)),
                "snapshot_time_to_max_drawdown_min": 0,
                "step": len(fired_prices),
                "tp1_shift": abs(drawdown_pct)
            }])
            recovery_odds = float(recovery_model.predict_proba(features)[0][1])
        else:
            recovery_odds = min(1.0, max(0.0, (row["RSI"] - 30) / 70))

        log["confidence_score"] = round(current_confidence, 4)
        log["recovery_odds"] = round(recovery_odds, 4)
        # Dummy tp1 proxy
        current_tp1_shift = abs(drawdown_pct)
        log["tp1_shift_sim"] = current_tp1_shift

        # TP1 feasibility guard
        if require_tp1_feasibility:
            if current_tp1_shift > max_tp1_shift_pct:
                log["rejection_reason"] = f"TP1 shift {current_tp1_shift:.2f}% exceeds max {max_tp1_shift_pct}%"
                steps.append(log)
                prev_row = row
                continue

        # Recovery odds guard
        if require_recovery_odds:
            if recovery_odds < min_recovery_probability:
                log["rejection_reason"] = f"Recovery odds {recovery_odds:.2f} below min {min_recovery_probability}"
                steps.append(log)
                prev_row = row
                continue

        # Confidence odds guard
        if min_confidence_odds > 0:
            if current_confidence < min_confidence_odds:
                log["rejection_reason"] = f"Confidence score {current_confidence:.2f} below min {min_confidence_odds}"
                steps.append(log)
                prev_row = row
                continue

        # Confidence override (hard)
        if use_confidence_override:
            if current_confidence < confidence_dca_guard:
                log["rejection_reason"] = f"Confidence override: {current_confidence:.2f} < {confidence_dca_guard}"
                steps.append(log)
                prev_row = row
                continue

        # Confidence override (soft)
        if use_soft_confidence_override:
            if current_confidence < soft_confidence_override:
                log["rejection_reason"] = f"Soft confidence override: {current_confidence:.2f} < {soft_confidence_override}"
                steps.append(log)
                prev_row = row
                continue

        # Step progress guard (simulate time/price/drawdown spacing)
        if step_progress_guard and last_fire_ts is not None:
            min_seconds_elapsed = step_progress_guard.get("min_seconds_elapsed", 0)
            min_price_change_pct = step_progress_guard.get("min_price_change_pct", 0)
            min_be_improvement_pct = step_progress_guard.get("min_be_improvement_pct", 0)
            seconds_elapsed = int(row["timestamp"]) - int(last_fire_ts)
            price_change_pct = abs((row["close"] - last_price) / last_price * 100) if last_price else 0
            be_improvement_pct = abs(drawdown_pct) - abs(last_drawdown_pct) if last_drawdown_pct is not None else 0
            if seconds_elapsed < min_seconds_elapsed:
                log["rejection_reason"] = f"Step progress: {seconds_elapsed}s < {min_seconds_elapsed}s"
                steps.append(log)
                prev_row = row
                continue
            if price_change_pct < min_price_change_pct:
                log["rejection_reason"] = f"Step progress: price change {price_change_pct:.2f}% < {min_price_change_pct}%"
                steps.append(log)
                prev_row = row
                continue
            if be_improvement_pct < min_be_improvement_pct:
                log["rejection_reason"] = f"Step progress: BE improvement {be_improvement_pct:.2f}% < {min_be_improvement_pct}%"
                steps.append(log)
                prev_row = row
                continue

        # Step repeat guard (legacy, for compatibility)
        if "step_repeat_guard" in config and last_fire:
            delta_conf = current_confidence - last_fire.get("confidence_score", 0)
            delta_tp1 = current_tp1_shift - last_fire.get("tp1_shift_sim", 0)
            min_conf = config["step_repeat_guard"].get("min_conf_delta", 0)
            min_tp1 = config["step_repeat_guard"].get("min_tp1_delta", 0)
            if delta_conf < min_conf and delta_tp1 < min_tp1:
                log["rejection_reason"] = "Step repeat thresholds not met"
                steps.append(log)
                prev_row = row
                continue

        # --- Simulate SAFU/ML exit model (dummy) ---
        if use_safu_exit_model:
            # Simulate ML model as: if RSI < (100*ml_exit_threshold), block
            if row["RSI"] < ml_exit_threshold * 100:
                log["rejection_reason"] = f"SAFU/ML exit: RSI {row['RSI']:.2f} < {ml_exit_threshold*100:.2f}"
                steps.append(log)
                prev_row = row
                continue

        # --- All gates passed ---
        log["decision"] = "FIRE"
        fired_prices.append(row["close"])
        avg_entry_price = sum(fired_prices) / len(fired_prices)
        log["avg_entry_price"] = round(avg_entry_price, 4)
        log["dca_count"] = len(fired_prices) - 1
        log["drawdown_pct"] = round((row["close"] - avg_entry_price) / avg_entry_price * 100, 2)
        # Store for guards
        last_fire = log.copy()
        last_fire_ts = int(row["timestamp"])
        last_price = row["close"]
        last_drawdown_pct = drawdown_pct
        steps.append(log)
        prev_row = row

    return steps


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--symbol", required=True)
    parser.add_argument("--tf", default="15m")
    parser.add_argument("--entry_time", type=int, required=True)
    parser.add_argument("--config", default="dca_config.yaml")
    args = parser.parse_args()

    df = load_klines(args.symbol, args.tf, args.entry_time)
    df = add_indicators(df)
    entry_price = df.iloc[0]["close"]

    with open(CONFIG_PATH, "r") as f:
        full_config = yaml.safe_load(f)
    print(f"✅ Loaded config keys: {list(full_config.keys())}")
    config = full_config.get("dca_config", full_config)

    CONFIDENCE_MODEL_PATH = BASE_DIR / "ml" / "models" / "xgb_confidence_model.pkl"
    RECOVERY_MODEL_PATH = BASE_DIR / "ml" / "models" / "xgb_model.pkl"

    try:
        confidence_model = joblib.load(CONFIDENCE_MODEL_PATH)
        recovery_model = joblib.load(RECOVERY_MODEL_PATH)
        print("✅ ML models loaded")
    except Exception as e:
        print(f"⚠️ Failed to load ML models: {e}")
        confidence_model = None
        recovery_model = None

    results = simulate_dca(df, entry_price, config, confidence_model, recovery_model)

    print(json.dumps(results, indent=2))

#!/usr/bin/env python3
import json
import argparse
from pathlib import Path
from datetime import datetime

MERGED_DIR = Path("/home/signal/market7/ml/merged")
CLEANED_PREFIX = "cleaned_flattened_"

REQUIRED_TRADE_FIELDS = ["entry_time", "exit_time", "entry_price", "exit_price"]

def is_valid_entry(entry):
    trade = entry.get("trade")
    fork = entry.get("fork")
    if not trade or not fork:
        return False
    if not isinstance(fork.get("raw_indicators"), dict):
        return False
    for field in REQUIRED_TRADE_FIELDS:
        if field not in trade:
            return False
    return True

def flatten_entry(entry):
    flat = {}

    trade = entry["trade"]
    fork = entry["fork"]
    indicators = fork["raw_indicators"]
    btc = entry.get("btc_context", {}).get("entry", {})
    tv = entry.get("tv_kicker", {})

    flat["symbol"] = trade.get("symbol")
    flat["entry_time"] = trade.get("entry_time")
    flat["exit_time"] = trade.get("exit_time")
    flat["entry_price"] = trade.get("entry_price")
    flat["exit_price"] = trade.get("exit_price")
    flat["pnl_pct"] = trade.get("pnl_pct")
    flat["safety_orders"] = trade.get("safety_orders")
    flat["status"] = trade.get("status")

    flat["fork_score"] = fork.get("score")
    for k, v in indicators.items():
        flat[f"ind_{k}"] = v
    for k, v in btc.items():
        flat[f"btc_{k}"] = v

    if tv:
        flat["tv_tag"] = tv.get("tv_tag")
        flat["tv_kicker"] = tv.get("tv_kicker")
        flat["tv_pass"] = tv.get("pass", False)

    return flat

def process_file(date_str):
    input_path = MERGED_DIR / f"merged_trades_{date_str}.jsonl"
    output_path = MERGED_DIR / f"{CLEANED_PREFIX}{date_str}.jsonl"

    if not input_path.exists():
        print(f"‚ùå Missing: {input_path}")
        return 0

    with open(input_path, "r") as f:
        raw = [json.loads(line) for line in f if line.strip()]
    cleaned = [flatten_entry(e) for e in raw if is_valid_entry(e)]

    with open(output_path, "w") as f:
        for row in cleaned:
            f.write(json.dumps(row) + "\n")

    print(f"‚úÖ {date_str}: Saved {len(cleaned)} rows ‚Üí {output_path.name}")
    return len(cleaned)

def main():
    parser = argparse.ArgumentParser(description="Clean and flatten merged trade files.")
    parser.add_argument("--date", help="Target date (YYYY-MM-DD)")
    parser.add_argument("--all", action="store_true", help="Process all matching merged_trades_*.jsonl files")
    args = parser.parse_args()

    if args.all:
        total = 0
        for file in sorted(MERGED_DIR.glob("merged_trades_*.jsonl")):
            date_part = file.stem.replace("merged_trades_", "")
            total += process_file(date_part)
        print(f"\nüì¶ Done! Total cleaned entries: {total}")
    elif args.date:
        process_file(args.date)
    else:
        print("‚ùå Please specify --date YYYY-MM-DD or --all")

if __name__ == "__main__":
    main()

#!/usr/bin/env python3
import json
import argparse
from datetime import datetime, timedelta, timezone
from pathlib import Path

# ─── CONFIG ────────────────────────────────────────────────────────────────
PROJECT_ROOT       = Path(__file__).resolve().parents[2]
PAPER_BASE         = PROJECT_ROOT/"ml"/"datasets"/"scrubbed_paper"
SCRUBBED_FORK_BASE = PROJECT_ROOT/"ml"/"datasets"/"fork_pulls"
RAW_FORK_BASE      = PROJECT_ROOT/"output"/"fork_history"
TV_BASE            = PROJECT_ROOT/"output"/"tv_history"
BTC_BASE           = PROJECT_ROOT/"dashboard_backend"/"btc_logs"
OUT_BASE           = PROJECT_ROOT/"ml"/"datasets"/"enriched"

# tolerances
FORK_GRACE_S = 1800   # 30m
BTC_GRACE_S  = 3600   # 1h

# ─── HELPERS ───────────────────────────────────────────────────────────────
def normalize(sym: str) -> str:
    s = sym.upper().strip()
    return s[:-4] if s.endswith("USDT") else s

def parse_iso(z: str) -> datetime:
    return datetime.strptime(z, "%Y-%m-%dT%H:%M:%SZ").replace(tzinfo=timezone.utc)

def load_jsonl(path: Path):
    if not path.exists(): return []
    with open(path) as f:
        return [json.loads(l) for l in f if l.strip()]

def close_enough(ts_ms, target_dt, grace_s):
    try:
        dt = datetime.fromtimestamp(int(ts_ms)/1000, tz=timezone.utc)
        return abs((dt - target_dt).total_seconds()) <= grace_s
    except:
        return False

def find_fork_record(symbol, entry_dt, days_back=7):
    base = normalize(symbol)
    for d_off in range(days_back+1):
        day = (entry_dt - timedelta(days=d_off)).strftime("%Y-%m-%d")
        # 1) scrubbed
        p1 = SCRUBBED_FORK_BASE/day/"scrubbed_fork_scores.jsonl"
        for r in load_jsonl(p1):
            if normalize(r.get("symbol",""))==base and close_enough(r["timestamp"], entry_dt, FORK_GRACE_S):
                return r
        # 2) raw
        p2 = RAW_FORK_BASE/day/"fork_scores.jsonl"
        raw = load_jsonl(p2)
        for r in raw:
            if normalize(r.get("symbol",""))==base and close_enough(r["timestamp"], entry_dt, FORK_GRACE_S):
                return r
        # 3) TV kicker
        p3 = TV_BASE/day/"tv_kicker.jsonl"
        for t in load_jsonl(p3):
            if t.get("pass") and normalize(t.get("symbol",""))==base and close_enough(t["timestamp"], entry_dt, FORK_GRACE_S):
                # merge into raw meta
                for r in raw:
                    if normalize(r.get("symbol",""))==base and close_enough(r["timestamp"], entry_dt, FORK_GRACE_S):
                        e = dict(r)
                        e.update({
                          "tv_kicker_applied": True,
                          "tv_tag": t.get("tv_tag"),
                          "tv_kicker": t.get("tv_kicker"),
                          "adjusted_score": t.get("adjusted_score"),
                          "tv_ts": t.get("timestamp"),
                          "tv_ts_iso": t.get("ts_iso"),
                        })
                        return e
    return None

def find_btc_snapshot(day, target_dt):
    snaps = load_jsonl(BTC_BASE/day/"btc_snapshots.jsonl")
    best, bd = None, 1e9
    for s in snaps:
        if "ts_iso" not in s: continue
        dt = datetime.fromisoformat(s["ts_iso"].replace("Z","+00:00"))
        diff = abs((dt - target_dt).total_seconds())
        if diff<bd and diff<=BTC_GRACE_S:
            best, bd = s, diff
    return best

# ─── MAIN ─────────────────────────────────────────────────────────────────
def main():
    p = argparse.ArgumentParser()
    p.add_argument("--date", required=True, help="Exit date YYYY-MM-DD")
    args = p.parse_args()
    exit_day = args.date
    out_dir = OUT_BASE/exit_day
    out_dir.mkdir(parents=True, exist_ok=True)

    trades = load_jsonl(PAPER_BASE/exit_day/"scrubbed_trades.jsonl")
    enriched, unmatched = [], []

    for t in trades:
        sym = t["symbol"]
        try:
            e_dt = parse_iso(t["entry_time"])
            x_dt = parse_iso(t["exit_time"])
        except:
            unmatched.append({**t, "reason":"bad_timestamp"})
            continue

        fork = find_fork_record(sym, e_dt, days_back=14)
        if not fork:
            unmatched.append({**t, "reason":"no_fork_found"})
            continue

        btc_e = find_btc_snapshot(e_dt.strftime("%Y-%m-%d"), e_dt)
        btc_x = find_btc_snapshot(x_dt.strftime("%Y-%m-%d"), x_dt)

        enriched.append({
            **t,
            "deal_id": t["trade_id"],
            "fork_score": fork,
            "btc_entry": btc_e,
            "btc_exit":  btc_x,
            "duration_min": round(abs((x_dt-e_dt).total_seconds())/60,2)
        })

    # write out
    with open(out_dir/"enriched_data.jsonl","w") as f:
        for r in enriched: f.write(json.dumps(r)+"\n")
    with open(out_dir/"unmatched_trades.jsonl","w") as f:
        for r in unmatched: f.write(json.dumps(r)+"\n")

    print(f"[DONE] enriched {len(enriched)} trades")
    print(f"[WARN] {len(unmatched)} unmatched → {out_dir/'unmatched_trades.jsonl'}")

if __name__=="__main__":
    main()

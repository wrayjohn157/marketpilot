#!/usr/bin/env python3
import json
import logging
from pathlib import Path
import argparse
import pandas as pd
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import classification_report
import joblib

# === Logging Setup ===
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# === Default Paths ===
BASE_DIR = Path(__file__).resolve().parents[2]  # ~/market7/
DEFAULT_MODEL_PATH = BASE_DIR / "ml/models/xgb_recovery_model.pkl"

# === Helper: Load and flatten JSONL ===
def load_jsonl_flat(path: Path) -> pd.DataFrame:
    data = []
    with open(path, "r") as f:
        for line in f:
            row = json.loads(line.strip())
            # Flatten snapshot_meta into top-level fields (if any)
            snapshot_meta = row.pop("snapshot_meta", {})
            for k, v in snapshot_meta.items():
                row[f"snapshot_{k}"] = v
            # Drop non-numeric / debug fields
            row.pop("symbol", None)
            row.pop("deal_id", None)
            row.pop("zombie_reason", None)
            data.append(row)
    return pd.DataFrame(data)

# === Trainer Function ===
def train_model(input_path: Path, output_model_path: Path):
    logging.info(f"üìÇ Loading dataset: {input_path}")
    df = load_jsonl_flat(input_path)

    if "recovery_label" not in df.columns:
        logging.error("‚ùå 'recovery_label' column not found. Exiting.")
        return

    df = df[df["recovery_label"].notna()]
    y = df["recovery_label"]
    X = df.drop(columns=[
        "recovery_label", 
        "status", 
        "exit_time", 
        "pnl_pct"  # Optional: drop if not used
    ], errors="ignore").fillna(0)

    logging.info(f"‚úÖ Dataset loaded: {X.shape[0]} samples, {X.shape[1]} features.")

    # Split data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    logging.info("üß† Training XGBoost classifier...")
    model = XGBClassifier(
        n_estimators=250,
        max_depth=5,
        learning_rate=0.05,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42,
        use_label_encoder=False,
        eval_metric="logloss"
    )
    model.fit(X_train, y_train)

    logging.info("üß™ Evaluating model...")
    y_pred = model.predict(X_test)
    report = classification_report(y_test, y_pred, digits=3)
    print("\nüìä Classification Report:\n", report)

    output_model_path.parent.mkdir(parents=True, exist_ok=True)
    joblib.dump(model, output_model_path)
    logging.info(f"‚úÖ Model saved to: {output_model_path}")

# === Main ===
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Train recovery ML model.")
    parser.add_argument("--input", type=Path, required=True, help="Merged recovery_training JSONL path")
    parser.add_argument("--output", type=Path, default=DEFAULT_MODEL_PATH, help="Where to save model (pkl)")
    args = parser.parse_args()

    train_model(args.input, args.output)

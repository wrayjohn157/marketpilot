#!/usr/bin/env python3
"""
Test script for Unified Configuration Manager
Tests environment detection, path resolution, config loading, and validation
"""

import asyncio
import json
import sys
import tempfile
from pathlib import Path
from typing import Dict, List

# Add current directory to path
sys.path.append(str(Path(__file__).parent))

from config.unified_config_manager import (
from config.unified_config_manager import get_path
from config.unified_config_manager import get_config
    UnifiedConfigManager,
    EnvironmentDetector,
    SmartDefaults,
    ConfigValidator,
    Environment,
    get_config_manager,
    get_path,
    get_config,
    get_all_paths,
    get_all_configs
)


def test_environment_detection():
    """Test environment detection"""
    print("ðŸ§ª Testing Environment Detection...")
    
    detector = EnvironmentDetector()
    env_info = detector.detect_environment()
    
    print(f"      Environment: {env_info.environment.value}")
    print(f"      Base Path: {env_info.base_path}")
    print(f"      Is Docker: {env_info.is_docker}")
    print(f"      Is Development: {env_info.is_development}")
    print(f"      Hostname: {env_info.hostname}")
    print(f"      Platform: {env_info.platform}")
    
    # Validate environment detection
    assert env_info.environment in Environment, f"Invalid environment: {env_info.environment}"
    assert env_info.base_path.exists() or env_info.is_development, f"Base path does not exist: {env_info.base_path}"
    
    print("      âœ… Environment detection working correctly")


def test_smart_defaults():
    """Test smart defaults generation"""
    print("\nðŸ§ª Testing Smart Defaults...")
    
    # Test path defaults
    defaults = SmartDefaults.get_default_paths(Environment.DEVELOPMENT, Path("/workspace"))
    
    required_keys = ["base", "snapshots", "fork_history", "btc_logs", "live_logs", "models"]
    for key in required_keys:
        assert key in defaults, f"Missing required path key: {key}"
        assert isinstance(defaults[key], Path), f"Path value not a Path object: {key}"
    
    print(f"      Generated {len(defaults)} default paths")
    
    # Test config defaults
    config_defaults = SmartDefaults.get_default_configs()
    
    required_configs = ["dca_config", "fork_safu_config", "tv_screener_config", "unified_pipeline_config", "ml_pipeline_config"]
    for config_name in required_configs:
        assert config_name in config_defaults, f"Missing required config: {config_name}"
        assert isinstance(config_defaults[config_name], dict), f"Config not a dict: {config_name}"
    
    print(f"      Generated {len(config_defaults)} default configs")
    print("      âœ… Smart defaults working correctly")


def test_config_validation():
    """Test config validation"""
    print("\nðŸ§ª Testing Config Validation...")
    
    validator = ConfigValidator()
    
    # Test path validation
    test_paths = {
        "base": Path("/workspace"),
        "snapshots": Path("/workspace/data/snapshots"),
        "invalid": Path("/invalid/path/that/does/not/exist"),
    }
    
    path_issues = validator.validate_paths(test_paths)
    print(f"      Path validation issues: {len(path_issues)}")
    for issue in path_issues:
        print(f"         - {issue}")
    
    # Test config validation
    test_config = {
        "min_score": 0.65,
        "max_dca_attempts": 5,
        "dca_volume_multiplier": 1.2,
        "weights": {
            "rsi_recovery": 0.25,
            "stoch_rsi_cross": 0.20,
            "macd_histogram": 0.15,
            "adx_rising": 0.15,
            "ema_price_reclaim": 0.10,
            "volume_penalty": 0.10,
            "mean_reversion": 0.05
        }
    }
    
    config_issues = validator.validate_config(test_config, "fork_safu_config")
    print(f"      Config validation issues: {len(config_issues)}")
    for issue in config_issues:
        print(f"         - {issue}")
    
    print("      âœ… Config validation working correctly")


def test_unified_config_manager():
    """Test unified config manager"""
    print("\nðŸ§ª Testing Unified Config Manager...")
    
    # Test with development environment
    config_manager = UnifiedConfigManager(Environment.DEVELOPMENT)
    
    # Test environment info
    env_info = config_manager.get_environment_info()
    print(f"      Environment: {env_info.environment.value}")
    print(f"      Base Path: {env_info.base_path}")
    
    # Test path access
    try:
        base_path = config_manager.get_path("base")
        print(f"      Base path: {base_path}")
        assert isinstance(base_path, Path), "Base path not a Path object"
    except KeyError as e:
        print(f"      âš ï¸  Missing path key: {e}")
    
    # Test config access
    try:
        dca_config = config_manager.get_config("dca_config")
        print(f"      DCA config: {len(dca_config)} items")
        assert isinstance(dca_config, dict), "DCA config not a dict"
    except KeyError as e:
        print(f"      âš ï¸  Missing config key: {e}")
    
    # Test all paths
    all_paths = config_manager.get_all_paths()
    print(f"      Total paths: {len(all_paths)}")
    
    # Test all configs
    all_configs = config_manager.get_all_configs()
    print(f"      Total configs: {len(all_configs)}")
    
    # Test validation
    is_valid = config_manager.is_valid()
    validation_issues = config_manager.get_validation_issues()
    
    print(f"      Config valid: {is_valid}")
    print(f"      Validation issues: {len(validation_issues)}")
    
    if validation_issues:
        print("      Validation issues:")
        for issue in validation_issues[:5]:  # Show first 5 issues
            print(f"         - {issue}")
        if len(validation_issues) > 5:
            print(f"         ... and {len(validation_issues) - 5} more")
    
    print("      âœ… Unified config manager working correctly")


def test_convenience_functions():
    """Test convenience functions"""
    print("\nðŸ§ª Testing Convenience Functions...")
    
    # Test get_config_manager
    manager = get_config_manager()
    assert isinstance(manager, UnifiedConfigManager), "get_config_manager not returning UnifiedConfigManager"
    
    # Test get_path
    try:
        base_path = get_path("base")
        assert isinstance(base_path, Path), "get_path not returning Path object"
        print(f"      get_path('base'): {base_path}")
    except KeyError:
        print("      âš ï¸  get_path('base') not available")
    
    # Test get_config
    try:
        dca_config = get_config("dca_config")
        assert isinstance(dca_config, dict), "get_config not returning dict"
        print(f"      get_config('dca_config'): {len(dca_config)} items")
    except KeyError:
        print("      âš ï¸  get_config('dca_config') not available")
    
    # Test get_all_paths
    all_paths = get_all_paths()
    assert isinstance(all_paths, dict), "get_all_paths not returning dict"
    print(f"      get_all_paths(): {len(all_paths)} paths")
    
    # Test get_all_configs
    all_configs = get_all_configs()
    assert isinstance(all_configs, dict), "get_all_configs not returning dict"
    print(f"      get_all_configs(): {len(all_configs)} configs")
    
    print("      âœ… Convenience functions working correctly")


def test_config_saving():
    """Test config saving functionality"""
    print("\nðŸ§ª Testing Config Saving...")
    
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)
        
        # Create a test config manager
        config_manager = UnifiedConfigManager(Environment.TESTING)
        
        # Override base path for testing
        config_manager.env_info.base_path = temp_path
        config_manager.paths["base"] = temp_path
        config_manager.paths["test_config"] = temp_path / "test_config.yaml"
        
        # Create test config
        test_config = {
            "test_key": "test_value",
            "test_number": 42,
            "test_nested": {
                "nested_key": "nested_value"
            }
        }
        
        # Add to configs
        config_manager.configs["test_config"] = test_config
        
        try:
            # Save config
            config_manager.save_config("test_config", test_config)
            
            # Verify file was created
            config_file = temp_path / "test_config.yaml"
            assert config_file.exists(), "Config file not created"
            
            # Verify content
            with open(config_file, 'r') as f:
                import yaml
                saved_config = yaml.safe_load(f)
            
            assert saved_config == test_config, "Saved config doesn't match original"
            print(f"      âœ… Config saved successfully to {config_file}")
            
        except Exception as e:
            print(f"      âŒ Config saving failed: {e}")


def test_environment_specific_paths():
    """Test environment-specific path resolution"""
    print("\nðŸ§ª Testing Environment-Specific Paths...")
    
    environments = [Environment.DEVELOPMENT, Environment.STAGING, Environment.PRODUCTION, Environment.TESTING]
    
    for env in environments:
        print(f"      Testing {env.value} environment...")
        
        # Get defaults for this environment
        expected_base = {
            Environment.DEVELOPMENT: Path("/workspace"),
            Environment.STAGING: Path("/opt/market7"),
            Environment.PRODUCTION: Path("/home/signal/market7"),
            Environment.TESTING: Path("/tmp/market7_test")
        }[env]
        
        defaults = SmartDefaults.get_default_paths(env, expected_base)
        
        assert defaults["base"] == expected_base, f"Wrong base path for {env.value}: {defaults['base']}"
        
        # Check that all required paths are present
        required_keys = ["base", "snapshots", "fork_history", "btc_logs", "live_logs", "models"]
        for key in required_keys:
            assert key in defaults, f"Missing required path {key} for {env.value}"
        
        print(f"         âœ… {env.value} paths configured correctly")


def test_error_handling():
    """Test error handling"""
    print("\nðŸ§ª Testing Error Handling...")
    
    config_manager = UnifiedConfigManager()
    
    # Test invalid path key
    try:
        config_manager.get_path("invalid_key")
        print("      âŒ Should have raised KeyError for invalid path key")
    except KeyError:
        print("      âœ… Correctly raised KeyError for invalid path key")
    
    # Test invalid config key
    try:
        config_manager.get_config("invalid_config")
        print("      âŒ Should have raised KeyError for invalid config key")
    except KeyError:
        print("      âœ… Correctly raised KeyError for invalid config key")
    
    # Test config validation with invalid data
    validator = ConfigValidator()
    
    invalid_config = {
        "min_score": 1.5,  # Invalid: should be between 0 and 1
        "max_dca_attempts": 15,  # Invalid: should be between 1 and 10
        "weights": {
            "rsi_recovery": 0.5,
            "stoch_rsi_cross": 0.5,
            "extra_weight": 0.5  # Invalid: weights should sum to 1.0
        }
    }
    
    issues = validator.validate_config(invalid_config, "fork_safu_config")
    assert len(issues) > 0, "Should have validation issues for invalid config"
    print(f"      âœ… Detected {len(issues)} validation issues in invalid config")
    
    print("      âœ… Error handling working correctly")


def test_performance():
    """Test performance"""
    print("\nðŸ§ª Testing Performance...")
    
    import time
    
    # Test config manager initialization time
    start_time = time.time()
    config_manager = UnifiedConfigManager()
    init_time = time.time() - start_time
    
    print(f"      Config manager initialization: {init_time:.3f} seconds")
    
    # Test path access performance
    start_time = time.time()
    for _ in range(100):
        try:
            config_manager.get_path("base")
        except KeyError:
            pass
    path_access_time = time.time() - start_time
    
    print(f"      100 path accesses: {path_access_time:.3f} seconds")
    
    # Test config access performance
    start_time = time.time()
    for _ in range(100):
        try:
            config_manager.get_config("dca_config")
        except KeyError:
            pass
    config_access_time = time.time() - start_time
    
    print(f"      100 config accesses: {config_access_time:.3f} seconds")
    
    # Performance should be reasonable
    if init_time < 1.0 and path_access_time < 0.1 and config_access_time < 0.1:
        print("      âœ… Performance is good")
    else:
        print("      âš ï¸  Performance could be improved")


async def main():
    """Run all tests"""
    print("ðŸš€ Unified Configuration Manager - Test Suite")
    print("=" * 60)
    
    try:
        test_environment_detection()
        test_smart_defaults()
        test_config_validation()
        test_unified_config_manager()
        test_convenience_functions()
        test_config_saving()
        test_environment_specific_paths()
        test_error_handling()
        test_performance()
        
        print("\nâœ… All tests completed successfully!")
        print("\nðŸ“‹ Key Features Demonstrated:")
        print("â€¢ Environment detection with multiple fallback strategies")
        print("â€¢ Smart defaults for all environments")
        print("â€¢ Comprehensive config validation")
        print("â€¢ Unified API for paths and configs")
        print("â€¢ Convenience functions for easy access")
        print("â€¢ Config saving and reloading")
        print("â€¢ Environment-specific path resolution")
        print("â€¢ Robust error handling")
        print("â€¢ Good performance characteristics")
        
        print("\nðŸš€ Benefits of Unified Config System:")
        print("â€¢ Eliminates hardcoded paths and scattered configs")
        print("â€¢ Provides environment-aware configuration")
        print("â€¢ Includes smart defaults and validation")
        print("â€¢ Offers consistent API across all systems")
        print("â€¢ Enables easy deployment across environments")
        print("â€¢ Reduces maintenance overhead with centralized management")
        
        print("\nðŸ“ˆ Next Steps:")
        print("1. Run migrate_to_unified_config.py to update all files")
        print("2. Test the migrated files in your environment")
        print("3. Add environment-specific configurations")
        print("4. Implement config validation in deployment pipeline")
        print("5. Create config management UI for easy editing")
        
    except Exception as e:
        print(f"\nâŒ Test failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())